{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cefb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:06:52.443737Z",
     "iopub.status.busy": "2025-05-19T13:06:52.443002Z",
     "iopub.status.idle": "2025-05-19T13:06:52.451057Z",
     "shell.execute_reply": "2025-05-19T13:06:52.450556Z",
     "shell.execute_reply.started": "2025-05-19T13:06:52.443708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cb6b1cc45d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "\n",
    "torch.manual_seed(42)z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf3a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:22:24.781390Z",
     "iopub.status.busy": "2025-05-19T13:22:24.780717Z",
     "iopub.status.idle": "2025-05-19T13:22:24.787071Z",
     "shell.execute_reply": "2025-05-19T13:22:24.786544Z",
     "shell.execute_reply.started": "2025-05-19T13:22:24.781366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBB_HyperParameters(object):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        self.lr = 1e-4 #1e-3, 1e-4, 1e-5\n",
    "        self.momentum = 0.95\n",
    "        self.hidden_units = 1200\n",
    "        self.pi = 0.75 # 0.75, 0.5, 0.25\n",
    "        self.s1 = float(np.exp(-1)) # exp(0), exp(-1), exp(-2)\n",
    "        self.s2 = float(np.exp(-8)) # exp(-6), exp(-7), exp(-8)\n",
    "        self.max_epoch = 200\n",
    "        self.n_test_samples = 10\n",
    "        self.batch_size = 128\n",
    "    \n",
    "\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (1. / (torch.sqrt(torch.tensor(2. * np.pi)) * sigma)) * torch.exp(- (x - mu) ** 2 / (2. * sigma ** 2))\n",
    "\n",
    "\n",
    "def mixture_prior(input, pi, s1, s2):\n",
    "    p1 = pi * gaussian(input, 0., s1)\n",
    "    p2 = (1. - pi) * gaussian(input, 0., s2)\n",
    "    return torch.log(p1 + p2)\n",
    "\n",
    "\n",
    "def log_gaussian_rho(x, mu, rho):\n",
    "    return float(-0.5 * np.log(2 * np.pi)) - rho - (x - mu) ** 2 / (2 * torch.exp(rho) ** 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524febc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:22:40.374436Z",
     "iopub.status.busy": "2025-05-19T13:22:40.373917Z",
     "iopub.status.idle": "2025-05-19T13:22:40.383004Z",
     "shell.execute_reply": "2025-05-19T13:22:40.382247Z",
     "shell.execute_reply.started": "2025-05-19T13:22:40.374413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBBLayer(nn.Module):\n",
    "    def __init__(self, n_input, n_output, hyper):\n",
    "        super(BBBLayer, self).__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.s1 = hyper.s1\n",
    "        self.s2 = hyper.s2\n",
    "        self.pi = hyper.pi\n",
    "\n",
    "        \n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(n_output, n_input))\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(n_output))\n",
    "\n",
    "        torch.nn.init.trunc_normal_(self.weight_mu, std=0.05)\n",
    "        torch.nn.init.constant_(self.bias_mu, 0.)\n",
    "\n",
    "        #torch.nn.init.kaiming_uniform_(self.weight_mu, nonlinearity='relu')\n",
    "        #fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight_mu)\n",
    "        #bound = 1 / math.sqrt(fan_in)\n",
    "        #torch.nn.init.uniform_(self.bias_mu, -bound, bound)\n",
    "        \n",
    "        # rho parameters\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(n_output, n_input).normal_(-6.5, 0.1))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(n_output).normal_(-6.5, 0.1))\n",
    "\n",
    "        #self.bias_rho = nn.Parameter(torch.Tensor(n_output).normal_(-8.0, .05))\n",
    "        #self.weight_rho = nn.Parameter(torch.Tensor(n_output, n_input).normal_(-8.0, .05))\n",
    "\n",
    "\n",
    "        self.log_prior = 0. \n",
    "        self.log_varpost = 0. \n",
    "\n",
    "    def forward(self, data, infer=False):\n",
    "        if infer:\n",
    "            output = F.linear(data, self.weight_mu, self.bias_mu)\n",
    "            return output\n",
    "\n",
    "        epsilon_W = Variable(torch.Tensor(self.n_output, self.n_input).normal_(0, 1).cuda())\n",
    "        epsilon_b = Variable(torch.Tensor(self.n_output).normal_(0, 1).cuda())\n",
    "        W = self.weight_mu + torch.log(1+torch.exp(self.weight_rho)) * epsilon_W\n",
    "        b = self.bias_mu + torch.log(1+torch.exp(self.bias_rho)) * epsilon_b\n",
    "\n",
    "        self.log_varpost = log_gaussian_rho(W, self.weight_mu, self.weight_rho).sum() + log_gaussian_rho(b, self.bias_mu, self.bias_rho).sum()\n",
    "        self.log_prior = mixture_prior(W, self.pi, self.s2, self.s1).sum() + mixture_prior(b, self.pi, self.s2, self.s1).sum()\n",
    "\n",
    "        output = F.linear(data, W, b)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1fbaad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:22.081926Z",
     "iopub.status.busy": "2025-05-19T13:08:22.081659Z",
     "iopub.status.idle": "2025-05-19T13:08:22.088369Z",
     "shell.execute_reply": "2025-05-19T13:08:22.087746Z",
     "shell.execute_reply.started": "2025-05-19T13:08:22.081906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBB(nn.Module):\n",
    "    def __init__(self, n_input, n_output, hyper):\n",
    "        super(BBB, self).__init__()\n",
    "\n",
    "        self.n_input = n_input\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(BBBLayer(n_input, hyper.hidden_units, hyper))\n",
    "        self.layers.append(BBBLayer(hyper.hidden_units, hyper.hidden_units, hyper))\n",
    "        self.layers.append(BBBLayer(hyper.hidden_units, n_output, hyper))\n",
    "\n",
    "    def forward(self, data, infer=False):\n",
    "        output = F.relu(self.layers[0](data.view(-1, self.n_input), infer))\n",
    "        output = F.relu(self.layers[1](output, infer))\n",
    "        output = F.softmax(self.layers[2](output, infer), dim=1)\n",
    "        return output\n",
    "\n",
    "    def get_prior_varpost(self):\n",
    "        log_prior = self.layers[0].log_prior + self.layers[1].log_prior + self.layers[2].log_prior\n",
    "        log_varpost = self.layers[0].log_varpost + self.layers[1].log_varpost + self.layers[2].log_varpost\n",
    "        return log_prior, log_varpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4bfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:24.927607Z",
     "iopub.status.busy": "2025-05-19T13:08:24.927337Z",
     "iopub.status.idle": "2025-05-19T13:08:24.932813Z",
     "shell.execute_reply": "2025-05-19T13:08:24.932070Z",
     "shell.execute_reply.started": "2025-05-19T13:08:24.927589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def MonteCarloSampling(model, data, target):\n",
    "    s_log_prior, s_log_varpost, s_log_likelihood = 0., 0., 0.\n",
    "\n",
    "    #print(model(data)[0])\n",
    "    \n",
    "    output = torch.log(model(data))\n",
    "\n",
    "    #print(f\"Log-Output: {output}\")\n",
    "\n",
    "    sample_log_prior, sample_log_varpost = model.get_prior_varpost()\n",
    "\n",
    "    #print(f\"log_prior: {sample_log_prior}, log_varpost: {sample_log_varpost}\")\n",
    "\n",
    "    \n",
    "    sample_log_likelihood = -F.nll_loss(output, target, reduction='sum')\n",
    "\n",
    "    #print(f\"log_likelihood: {sample_log_likelihood}\")\n",
    "\n",
    "    s_log_prior += sample_log_prior \n",
    "    s_log_varpost += sample_log_varpost \n",
    "    s_log_likelihood += sample_log_likelihood\n",
    "\n",
    "    return s_log_prior, s_log_varpost, s_log_likelihood\n",
    "\n",
    "\n",
    "def ELBO(log_prior, log_varpost, l_likelihood, m):\n",
    "    kl = (1/m) * (log_varpost - log_prior)\n",
    "    return kl - l_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8f5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:26.656744Z",
     "iopub.status.busy": "2025-05-19T13:08:26.656029Z",
     "iopub.status.idle": "2025-05-19T13:08:26.663635Z",
     "shell.execute_reply": "2025-05-19T13:08:26.662814Z",
     "shell.execute_reply.started": "2025-05-19T13:08:26.656718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader, train=True):\n",
    "    loss_sum = 0\n",
    "    kl_sum = 0\n",
    "    m = len(loader)\n",
    "\n",
    "    for batch_id, (data, target) in enumerate(loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_prior, log_varpost, l_likelihood = MonteCarloSampling(model, data, target)\n",
    "        loss = ELBO(log_prior, log_varpost, l_likelihood, m)\n",
    "        loss_sum += loss / m\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        else:\n",
    "            kl_sum += (1. / m) * (log_varpost - log_prior)\n",
    "    if train:\n",
    "        return loss_sum\n",
    "    else:\n",
    "        return kl_sum\n",
    "\n",
    "def evaluate(model, loader, infer=True, samples=1):\n",
    "    acc_sum = 0\n",
    "    for idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        if samples == 1:\n",
    "            output = model(data, infer=infer)\n",
    "        else:\n",
    "            output = model(data)\n",
    "            for i in range(samples - 1):\n",
    "                output += model(data)\n",
    "\n",
    "        predict = output.data.max(1)[1]\n",
    "        acc = predict.eq(target.data).cpu().sum().item()\n",
    "        acc_sum += acc\n",
    "    return acc_sum / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207692bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:28.923440Z",
     "iopub.status.busy": "2025-05-19T13:08:28.923163Z",
     "iopub.status.idle": "2025-05-19T13:08:28.929037Z",
     "shell.execute_reply": "2025-05-19T13:08:28.928269Z",
     "shell.execute_reply.started": "2025-05-19T13:08:28.923421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def BBB_run(hyper, train_loader, valid_loader, test_loader, n_input, n_output):\n",
    "    \n",
    "    model = BBB(n_input, n_output, hyper).cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=hyper.lr, momentum=hyper.momentum)\n",
    "\n",
    "    train_losses = np.zeros(hyper.max_epoch)\n",
    "    valid_accs = np.zeros(hyper.max_epoch)\n",
    "    test_accs = np.zeros(hyper.max_epoch)\n",
    "\n",
    "    for epoch in range(hyper.max_epoch):\n",
    "        train_loss = train(model, optimizer, train_loader)\n",
    "        valid_acc = evaluate(model, valid_loader)\n",
    "        test_acc = evaluate(model, test_loader)\n",
    "\n",
    "        print('Epoch', epoch + 1, 'Loss', float(train_loss),\n",
    "              'Valid Error', round(100 * (1 - valid_acc / hyper.batch_size), 3), '%',\n",
    "              'Test Error',  round(100 * (1 - test_acc / hyper.batch_size), 3), '%')\n",
    "\n",
    "        valid_accs[epoch] = valid_acc\n",
    "        test_accs[epoch] = test_acc\n",
    "        train_losses[epoch] = train_loss\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b323e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:22:44.213455Z",
     "iopub.status.busy": "2025-05-19T13:22:44.212826Z",
     "iopub.status.idle": "2025-05-19T13:25:55.955612Z",
     "shell.execute_reply": "2025-05-19T13:25:55.954532Z",
     "shell.execute_reply.started": "2025-05-19T13:22:44.213433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 39185.60546875 Valid Error 4.658 % Test Error 4.47 %\n",
      "Epoch 2 Loss 39175.44140625 Valid Error 4.015 % Test Error 4.015 %\n",
      "Epoch 3 Loss 39158.37109375 Valid Error 3.807 % Test Error 3.323 %\n",
      "Epoch 4 Loss 39142.76953125 Valid Error 3.847 % Test Error 3.619 %\n",
      "Epoch 5 Loss 39127.765625 Valid Error 3.343 % Test Error 2.957 %\n",
      "Epoch 6 Loss 39113.66015625 Valid Error 3.323 % Test Error 3.006 %\n",
      "Epoch 7 Loss 39099.45703125 Valid Error 3.333 % Test Error 2.967 %\n",
      "Epoch 8 Loss 39085.40625 Valid Error 3.303 % Test Error 2.907 %\n",
      "Epoch 9 Loss 39071.20703125 Valid Error 3.293 % Test Error 3.006 %\n",
      "Epoch 10 Loss 39057.35546875 Valid Error 3.313 % Test Error 2.878 %\n",
      "Epoch 11 Loss 39043.5625 Valid Error 3.214 % Test Error 2.878 %\n",
      "Epoch 12 Loss 39029.8515625 Valid Error 3.244 % Test Error 2.917 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3013157185.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBBB_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_ouput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_35/969048865.py\u001b[0m in \u001b[0;36mBBB_run\u001b[0;34m(hyper, train_loader, valid_loader, test_loader, n_input, n_output)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/3895030167.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loader, train)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mlog_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_varpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_likelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonteCarloSampling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mELBO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_varpost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_likelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1485537001.py\u001b[0m in \u001b[0;36mMonteCarloSampling\u001b[0;34m(model, data, target)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(model(data)[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(f\"Log-Output: {output}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1765840040.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, infer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/1183723127.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, infer)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mepsilon_W\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mepsilon_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_mu\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_rho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mepsilon_W\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: x  / 126.),  \n",
    "        ])\n",
    "\n",
    "\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "\n",
    "n_input = 28 * 28\n",
    "n_ouput = 10\n",
    "\n",
    "split_size = 1/6\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_set, validaton_set= torch.utils.data.random_split(train_data, [1 - split_size, split_size], generator=generator)\n",
    "\n",
    "\n",
    "hyper = BBB_HyperParameters()\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=hyper.batch_size, shuffle=True, num_workers=1)\n",
    "valid_loader = DataLoader(validaton_set, batch_size=hyper.batch_size, shuffle=True, num_workers=1)\n",
    "test_loader = DataLoader(test_data, batch_size=hyper.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "model = BBB_run(hyper, train_loader, valid_loader, test_loader, n_input, n_ouput)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
