{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "001cefb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:06:52.443737Z",
     "iopub.status.busy": "2025-05-19T13:06:52.443002Z",
     "iopub.status.idle": "2025-05-19T13:06:52.451057Z",
     "shell.execute_reply": "2025-05-19T13:06:52.450556Z",
     "shell.execute_reply.started": "2025-05-19T13:06:52.443708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7cb6b1cc45d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import datasets\n",
    "\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf3a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:22:24.781390Z",
     "iopub.status.busy": "2025-05-19T13:22:24.780717Z",
     "iopub.status.idle": "2025-05-19T13:22:24.787071Z",
     "shell.execute_reply": "2025-05-19T13:22:24.786544Z",
     "shell.execute_reply.started": "2025-05-19T13:22:24.781366Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBB_HyperParameters(object):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        self.lr = 1e-4 #1e-3, 1e-4, 1e-5\n",
    "        self.momentum = 0.95\n",
    "        self.hidden_units = 1200\n",
    "        self.pi = 0.75 # 0.75, 0.5, 0.25\n",
    "        self.s1 = float(np.exp(-1)) # exp(0), exp(-1), exp(-2)\n",
    "        self.s2 = float(np.exp(-8)) # exp(-6), exp(-7), exp(-8)\n",
    "        self.max_epoch = 600\n",
    "        self.batch_size = 128\n",
    "    \n",
    "\n",
    "\n",
    "def gaussian(x, mu, sigma):\n",
    "    return (1. / (torch.sqrt(torch.tensor(2. * np.pi)) * sigma)) * torch.exp(- (x - mu) ** 2 / (2. * sigma ** 2))\n",
    "\n",
    "\n",
    "def mixture_prior(input, pi, s1, s2):\n",
    "    p1 = pi * gaussian(input, 0., s1)\n",
    "    p2 = (1. - pi) * gaussian(input, 0., s2)\n",
    "    return torch.log(p1 + p2)\n",
    "\n",
    "\n",
    "def log_gaussian_rho(x, mu, rho):\n",
    "    return float(-0.5 * np.log(2 * np.pi)) - rho - (x - mu) ** 2 / (2 * torch.exp(rho) ** 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f524febc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:22:40.374436Z",
     "iopub.status.busy": "2025-05-19T13:22:40.373917Z",
     "iopub.status.idle": "2025-05-19T13:22:40.383004Z",
     "shell.execute_reply": "2025-05-19T13:22:40.382247Z",
     "shell.execute_reply.started": "2025-05-19T13:22:40.374413Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBBLayer(nn.Module):\n",
    "    def __init__(self, n_input, n_output, hyper):\n",
    "        super(BBBLayer, self).__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "\n",
    "        self.s1 = hyper.s1\n",
    "        self.s2 = hyper.s2\n",
    "        self.pi = hyper.pi\n",
    "\n",
    "        \n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(n_output, n_input))\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(n_output))\n",
    "\n",
    "        torch.nn.init.trunc_normal_(self.weight_mu, std=0.05)\n",
    "        torch.nn.init.constant_(self.bias_mu, 0.)\n",
    "\n",
    "        #torch.nn.init.kaiming_uniform_(self.weight_mu, nonlinearity='relu')\n",
    "        #fan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(self.weight_mu)\n",
    "        #bound = 1 / math.sqrt(fan_in)\n",
    "        #torch.nn.init.uniform_(self.bias_mu, -bound, bound)\n",
    "        \n",
    "        # rho parameters\n",
    "        self.weight_rho = nn.Parameter(torch.Tensor(n_output, n_input).normal_(-6.5, 0.1))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(n_output).normal_(-6.5, 0.1))\n",
    "\n",
    "        #self.bias_rho = nn.Parameter(torch.Tensor(n_output).normal_(-8.0, .05))\n",
    "        #self.weight_rho = nn.Parameter(torch.Tensor(n_output, n_input).normal_(-8.0, .05))\n",
    "\n",
    "\n",
    "        self.log_prior = 0. \n",
    "        self.log_varpost = 0. \n",
    "\n",
    "    def forward(self, data, infer=False):\n",
    "        if infer:\n",
    "            output = F.linear(data, self.weight_mu, self.bias_mu)\n",
    "            return output\n",
    "\n",
    "        epsilon_W = Variable(torch.Tensor(self.n_output, self.n_input).normal_(0., 1.).cuda())\n",
    "        epsilon_b = Variable(torch.Tensor(self.n_output).normal_(0., 1.).cuda())\n",
    "        W = self.weight_mu + torch.log(1+torch.exp(self.weight_rho)) * epsilon_W\n",
    "        b = self.bias_mu + torch.log(1+torch.exp(self.bias_rho)) * epsilon_b\n",
    "\n",
    "        self.log_varpost = log_gaussian_rho(W, self.weight_mu, self.weight_rho).sum() + log_gaussian_rho(b, self.bias_mu, self.bias_rho).sum()\n",
    "        self.log_prior = mixture_prior(W, self.pi, self.s2, self.s1).sum() + mixture_prior(b, self.pi, self.s2, self.s1).sum()\n",
    "\n",
    "        output = F.linear(data, W, b)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1fbaad7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:22.081926Z",
     "iopub.status.busy": "2025-05-19T13:08:22.081659Z",
     "iopub.status.idle": "2025-05-19T13:08:22.088369Z",
     "shell.execute_reply": "2025-05-19T13:08:22.087746Z",
     "shell.execute_reply.started": "2025-05-19T13:08:22.081906Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BBB(nn.Module):\n",
    "    def __init__(self, n_input, n_output, hyper):\n",
    "        super(BBB, self).__init__()\n",
    "\n",
    "        self.n_input = n_input\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.layers.append(BBBLayer(n_input, hyper.hidden_units, hyper))\n",
    "        self.layers.append(BBBLayer(hyper.hidden_units, hyper.hidden_units, hyper))\n",
    "        self.layers.append(BBBLayer(hyper.hidden_units, n_output, hyper))\n",
    "\n",
    "    def forward(self, data, infer=False):\n",
    "        output = F.relu(self.layers[0](data.view(-1, self.n_input), infer))\n",
    "        output = F.relu(self.layers[1](output, infer))\n",
    "        output = F.softmax(self.layers[2](output, infer), dim=1)\n",
    "        return output\n",
    "\n",
    "    def get_prior_varpost(self):\n",
    "        log_prior = self.layers[0].log_prior + self.layers[1].log_prior + self.layers[2].log_prior\n",
    "        log_varpost = self.layers[0].log_varpost + self.layers[1].log_varpost + self.layers[2].log_varpost\n",
    "        return log_prior, log_varpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4bfb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:24.927607Z",
     "iopub.status.busy": "2025-05-19T13:08:24.927337Z",
     "iopub.status.idle": "2025-05-19T13:08:24.932813Z",
     "shell.execute_reply": "2025-05-19T13:08:24.932070Z",
     "shell.execute_reply.started": "2025-05-19T13:08:24.927589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def MonteCarloSampling(model, data, target):\n",
    "    s_log_prior, s_log_varpost, s_log_likelihood = 0., 0., 0.\n",
    "\n",
    "    #print(model(data)[0])\n",
    "    \n",
    "    output = torch.log(model(data))\n",
    "\n",
    "    #print(f\"Log-Output: {output}\")\n",
    "\n",
    "    sample_log_prior, sample_log_varpost = model.get_prior_varpost()\n",
    "\n",
    "    #print(f\"log_prior: {sample_log_prior}, log_varpost: {sample_log_varpost}\")\n",
    "\n",
    "    \n",
    "    sample_log_likelihood = -F.nll_loss(output, target, reduction='sum')\n",
    "\n",
    "    #print(f\"log_likelihood: {sample_log_likelihood}\")\n",
    "\n",
    "    s_log_prior += sample_log_prior \n",
    "    s_log_varpost += sample_log_varpost \n",
    "    s_log_likelihood += sample_log_likelihood\n",
    "\n",
    "    return s_log_prior, s_log_varpost, s_log_likelihood\n",
    "\n",
    "\n",
    "def ELBO(log_prior, log_varpost, l_likelihood, pi_i):\n",
    "    kl = pi_i * (log_varpost - log_prior)\n",
    "    return kl - l_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8f5a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:26.656744Z",
     "iopub.status.busy": "2025-05-19T13:08:26.656029Z",
     "iopub.status.idle": "2025-05-19T13:08:26.663635Z",
     "shell.execute_reply": "2025-05-19T13:08:26.662814Z",
     "shell.execute_reply.started": "2025-05-19T13:08:26.656718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, loader):\n",
    "    loss_sum = 0\n",
    "    m = len(loader)\n",
    "\n",
    "    for i, (data, target) in enumerate(loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        log_prior, log_varpost, l_likelihood = MonteCarloSampling(model, data, target)\n",
    "        pi_i = (2. **(m - i - 1)) / (2. **(m) - 1)\n",
    "\n",
    "        loss = ELBO(log_prior, log_varpost, l_likelihood, pi_i)\n",
    "        loss_sum += loss / m\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    return loss_sum\n",
    "   \n",
    "\n",
    "def evaluate(model, loader, infer=True, samples=1):\n",
    "    acc_sum = 0\n",
    "    for idx, (data, target) in enumerate(loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        if samples == 1:\n",
    "            output = model(data, infer=infer)\n",
    "        \n",
    "\n",
    "        predict = output.data.max(1)[1]\n",
    "        acc = predict.eq(target.data).cpu().sum().item()\n",
    "        acc_sum += acc\n",
    "    return acc_sum / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "207692bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T13:08:28.923440Z",
     "iopub.status.busy": "2025-05-19T13:08:28.923163Z",
     "iopub.status.idle": "2025-05-19T13:08:28.929037Z",
     "shell.execute_reply": "2025-05-19T13:08:28.928269Z",
     "shell.execute_reply.started": "2025-05-19T13:08:28.923421Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def BBB_run(hyper, train_loader, valid_loader, test_loader, n_input, n_output):\n",
    "    \n",
    "    model = BBB(n_input, n_output, hyper).cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=hyper.lr, momentum=hyper.momentum)\n",
    "\n",
    "    train_losses = np.zeros(hyper.max_epoch)\n",
    "    valid_accs = np.zeros(hyper.max_epoch)\n",
    "    test_accs = np.zeros(hyper.max_epoch)\n",
    "\n",
    "    for epoch in range(hyper.max_epoch):\n",
    "        train_loss = train(model, optimizer, train_loader)\n",
    "        valid_acc = evaluate(model, valid_loader)\n",
    "        test_acc = evaluate(model, test_loader)\n",
    "\n",
    "        print('Epoch', epoch + 1, 'Loss', float(train_loss),\n",
    "              'Valid Error', round(100 * (1 - valid_acc / hyper.batch_size), 3), '%',\n",
    "              'Test Error',  round(100 * (1 - test_acc / hyper.batch_size), 3), '%')\n",
    "\n",
    "        valid_accs[epoch] = valid_acc\n",
    "        test_accs[epoch] = test_acc\n",
    "        train_losses[epoch] = train_loss\n",
    "\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
